# Base de conocimientos inicial
hechos = {
    "en_escena": True,
    "huellas_en_arma": True,
    "coartada": False  # Inicialmente no hay coartada
}

# Regla deductiva
def es_culpable(hechos):
    if hechos["en_escena"] and hechos["huellas_en_arma"] and not hechos["coartada"]:
        return "Culpable"
    else:
        return "No culpable"

# Conclusi칩n inicial
print("Conclusi칩n inicial:", es_culpable(hechos))

# Nueva informaci칩n: Coartada verificada
hechos["coartada"] = True

# Conclusi칩n revisada
print("Conclusi칩n revisada:", es_culpable(hechos))

class DefaultLogic:
    def __init__(self):
        self.facts = set()  # Conjunto de hechos conocidos
        self.exceptions = set()  # Conjunto de excepciones

    def add_fact(self, fact):
        """ Agrega un hecho al conocimiento """
        self.facts.add(fact)

    def add_exception(self, exception):
        """ Agrega una excepci칩n a una regla """
        self.exceptions.add(exception)

    def infer(self, entity, default_rule):
        """ Realiza una inferencia usando l칩gica por defecto """
        prereq, assumption, conclusion = default_rule
        if prereq in self.facts and assumption not in self.exceptions:
            return conclusion
        return "No se puede inferir"

# ---- DEMOSTRACI칍N ----
logic = DefaultLogic()

# Hecho conocido: Tweety es un p치jaro
logic.add_fact("es_pajaro_Tweety")

# Regla por defecto: Si es un p치jaro y no hay evidencia de que no vuele, entonces puede volar.
default_rule = ("es_pajaro_Tweety", "no_vuela_Tweety", "vuela_Tweety")

# Inferimos si Tweety puede volar
print(logic.infer("Tweety", default_rule))  # Output: "vuela_Tweety"


# Ahora agregamos una excepci칩n (descubrimos que es un ping칲ino)
logic.add_exception("no_vuela_Tweety")

# Volvemos a inferir
print(logic.infer("Tweety", default_rule))  # Output: "No se puede inferir"

class Circumscription:
    def __init__(self):
        self.evidence = {}  # Almacena hechos expl칤citos

    def add_fact(self, entity, property, value):
        """ Agrega un hecho expl칤cito """
        if entity not in self.evidence:
            self.evidence[entity] = {}
        self.evidence[entity][property] = value

    def query(self, entity, property):
        """ Solo devuelve una conclusi칩n si hay evidencia expl칤cita """
        return self.evidence.get(entity, {}).get(property, "No se puede inferir")

# ---- DEMOSTRACI칍N ----
circ = Circumscription()

# No hay informaci칩n sobre Juan
print(circ.query("Juan", "culpable"))  # Output: "No se puede inferir"
print(circ.query("Juan", "inocente"))  # Output: "No se puede inferir"

# Agregamos un hecho expl칤cito: Juan es inocente
circ.add_fact("Juan", "inocente", True)

# Ahora podemos inferir que Juan es inocente
print(circ.query("Juan", "inocente"))  # Output: True
print(circ.query("Juan", "culpable"))  # Output: "No se puede inferir"

# Agregamos un hecho expl칤cito de que Mar칤a es culpable
circ.add_fact("Maria", "culpable", True)

# Podemos consultar sobre Mar칤a
print(circ.query("Maria", "culpable"))  # Output: True
print(circ.query("Maria", "inocente"))  # Output: "No se puede inferir"

class AutoepistemicReasoning:
    def __init__(self):
        self.knowledge = set()  # Conjunto de hechos conocidos

    def add_knowledge(self, fact):
        """ Agrega un hecho expl칤cito al conocimiento """
        self.knowledge.add(fact)

    def knows(self, fact):
        """ Retorna True si el agente SABE que el hecho es verdadero """
        return fact in self.knowledge

    def does_not_know(self, fact):
        """ Retorna True si el agente NO SABE que el hecho es verdadero """
        return fact not in self.knowledge

    def infer(self, fact, assumption):
        """
        Inferencia autoepist칠mica:
        Si NO sabemos que una negaci칩n es cierta, asumimos que el hecho es verdadero.
        """
        if self.does_not_know(f"not_{fact}"):
            return assumption
        return False

# ---- DEMOSTRACI칍N ----
agent = AutoepistemicReasoning()

# Preguntamos si sabe que NO hay taxis
print(agent.knows("not_taxis"))  # False (el agente no tiene evidencia de que no hay taxis)

# Aplicamos la regla: "Si NO sabe que no hay taxis, asume que hay taxis"
taxis_available = agent.infer("taxis", True)
print(f"쮿ay taxis disponibles?: {taxis_available}")  # True


# Ahora agregamos conocimiento expl칤cito de que no hay taxis
agent.add_knowledge("not_taxis")

# Aplicamos la regla nuevamente
taxis_available = agent.infer("taxis", True)
print(f"쮿ay taxis disponibles?: {taxis_available}")  # False

class BeliefBase:
    def __init__(self):
        self.beliefs = set()

    def expand(self, belief):
        """A침ade una nueva creencia sin modificar las anteriores"""
        self.beliefs.add(belief)

    def contract(self, belief):
        """Elimina una creencia"""
        if belief in self.beliefs:
            self.beliefs.remove(belief)

    def revise(self, new_belief):
        """Revisa las creencias, eliminando contradicciones si es necesario"""
        contradicciones = {b for b in self.beliefs if self.is_contradiction(b, new_belief)}

        if contradicciones:
            print(f"丘멆잺 Se encontraron contradicciones: {contradicciones}. Ajustando creencias...")
            self.beliefs -= contradicciones  # Eliminar creencias contradictorias

        self.beliefs.add(new_belief)

    def is_contradiction(self, belief1, belief2):
        """Define cu치ndo dos creencias son contradictorias"""
        return belief1 == f"춻{belief2}" or belief2 == f"춻{belief1}"

    def show_beliefs(self):
        """Muestra el conjunto actual de creencias"""
        print("游늷 Creencias actuales:", self.beliefs)

# --- Ejemplo de uso ---
beliefs = BeliefBase()
beliefs.expand("Los p치jaros vuelan")
beliefs.expand("Tweety es un p치jaro")
beliefs.show_beliefs()


# Ahora aprendemos que "Tweety NO vuela" (porque es un ping칲ino)
beliefs.revise("춻(Tweety vuela)")
beliefs.show_beliefs()